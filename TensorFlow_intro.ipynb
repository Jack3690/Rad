{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOosnGAzasJfHZU3rymABDe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jack3690/Rad/blob/master/TensorFlow_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvHBpL4ho0zs"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDaIRMDsMOWQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.framework import ops\n",
        "import math"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-ue7qDWMP2g"
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "\n",
        "    X = tf.placeholder(tf.float32,(n_x,None),name='X')\n",
        "    Y = tf.placeholder(tf.float32,(n_y,None),name='Y')\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7KEH5wGMP-K"
      },
      "source": [
        "def initialize_parameters(Layer_dims):\n",
        "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
        "\n",
        "    parameters={}\n",
        "    L=len(Layer_dims)  \n",
        "\n",
        "    for l in range(1,L):\n",
        "        parameters['W'+str(l)] = tf.get_variable(\"W\"+str(l), [Layer_dims[l],Layer_dims[l-1]], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
        "        parameters['b'+str(l)] = tf.get_variable(\"b\" +str(l), [Layer_dims[l],1], initializer = tf.zeros_initializer())\n",
        "   \n",
        "    return parameters"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee1EEHr5rtnA",
        "outputId": "787071ce-0c80-426c-f2a1-ace35d274c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "parameters"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>,\n",
              " 'W2': <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>,\n",
              " 'W3': <tf.Variable 'W3:0' shape=(2, 12) dtype=float32_ref>,\n",
              " 'b1': <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>,\n",
              " 'b2': <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>,\n",
              " 'b3': <tf.Variable 'b3:0' shape=(2, 1) dtype=float32_ref>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F-Y-zDDOyqQ"
      },
      "source": [
        "def convert_to_one_hot(labels, C):\n",
        "    \"\"\"\n",
        "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
        "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
        "                     will be 1. \n",
        "                     \n",
        "    Arguments:\n",
        "    labels -- vector containing the labels \n",
        "    C -- number of classes, the depth of the one hot dimension\n",
        "    \n",
        "    Returns: \n",
        "    one_hot -- one hot matrix\n",
        "    \"\"\"\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
        "    C = tf.constant(C,name='C')\n",
        "    \n",
        "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
        "    one_hot_matrix = tf.one_hot(labels, C,axis=0)\n",
        "    \n",
        "    # Create the session (approx. 1 line)\n",
        "    sess = tf.Session()\n",
        "    \n",
        "    # Run the session (approx. 1 line)\n",
        "    one_hot = sess.run(one_hot_matrix )\n",
        "    \n",
        "    # Close the session (approx. 1 line). See method 1 above.\n",
        "    sess.close()\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return one_hot.squeeze()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkgFwY1iMQB8"
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "\n",
        "    L=len(parameters)//2\n",
        "    A=X\n",
        "    for l in range(1,L+1):\n",
        "      Z= tf.matmul(parameters[\"W\"+ str(l)],A) + parameters[\"b\"+ str(l)]\n",
        "      A= tf.nn.relu(Z)  \n",
        "    ZL=Z\n",
        "    return ZL"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbIXvq7AMP7r"
      },
      "source": [
        "def compute_cost(ZL, Y):\n",
        "    \n",
        "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
        "    logits = tf.transpose(ZL)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    ### START CODE HERE ### (1 line of code)\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEt1MD5pqfaV"
      },
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkAMmMSqMP5e"
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test,Layer_dims,learning_rate = 0.0001, num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
        " \n",
        "\n",
        "    \n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    tf.set_random_seed(1)                             # to keep consistent results\n",
        "    seed = 3                                          # to keep consistent results\n",
        "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "    n_y = Y_train.shape[0]                            # n_y : output size\n",
        "    costs = []                                        # To keep track of the cost\n",
        "    \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Initialize parameters\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    parameters = initialize_parameters(Layer_dims)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    ZL = forward_propagation(X, parameters)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    cost = compute_cost(ZL, Y)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
        "                ### START CODE HERE ### (1 line)\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "                ### END CODE HERE ###\n",
        "                \n",
        "                epoch_cost += minibatch_cost / minibatch_size\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per fives)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(ZL), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWEKOy0AvA_f"
      },
      "source": [
        "def predict(X, parameters):\n",
        "\n",
        "    L=len(parameters)//2\n",
        "    params={}\n",
        "    \n",
        "    for l in range(1,L):\n",
        "      params['W'+str(l)] = tf.convert_to_tensor(parameters[\"W\" +str(l)])\n",
        "      params['b'+str(l)] = tf.convert_to_tensor(parameters[\"b\" +str(l)])\n",
        "    x = tf.placeholder(\"float\", [12288, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1_xvIVtYMin"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "def load_data(file):\n",
        "  hf = h5py.File(file, 'r')\n",
        "  classes =hf.get(list(hf.keys())[0])\n",
        "  x_data=np.array(hf[list(hf.keys())[1]])\n",
        "  y_data=np.array(hf[list(hf.keys())[2]])\n",
        "  y_data=y_data.reshape(y_data.shape[0],1).T\n",
        "  return classes,x_data,y_data"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp62oYPSPRP6",
        "outputId": "91c667d8-89aa-48d8-c88e-d8bb3c84ab28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/Jack3690/Rad/"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Rad'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 86 (delta 36), reused 41 (delta 13), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXUXYCTQYhb-"
      },
      "source": [
        "classes,X_train_orig,Y_train_orig=load_data('Rad/train_catvnoncat.h5')\n",
        "_,X_test_orig,Y_test_orig=load_data('Rad/test_catvnoncat.h5')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt1SnnEuYhlK",
        "outputId": "dfe89ae1-a8cf-4518-b7ac-175f53a95141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x_flatten=X_train_orig.reshape(X_train_orig.shape[0],-1).T\n",
        "test_x_flatten=X_test_orig.reshape(X_test_orig.shape[0],-1).T\n",
        "X_train=train_x_flatten/255\n",
        "X_test=test_x_flatten/255\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 2)\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 2)\n",
        "print(X_train.shape,Y_train.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12288, 209) (2, 209)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg4Cq6Jjofgt"
      },
      "source": [
        "Layer_dims=[12288,20,7,5,2]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HaBT9q3Njyg",
        "outputId": "620180f4-0f41-4e33-9f3c-7756a510b28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "parameters = model(X_train, Y_train, X_test, Y_test,Layer_dims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 0.154007\n",
            "Cost after epoch 100: 0.073201\n",
            "Cost after epoch 200: 0.038071\n",
            "Cost after epoch 300: 0.021238\n",
            "Cost after epoch 400: 0.012709\n",
            "Cost after epoch 500: 0.008333\n",
            "Cost after epoch 600: 0.005724\n",
            "Cost after epoch 700: 0.003790\n",
            "Cost after epoch 800: 0.001372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxO9BGVRNj1l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjdPMtN9NjwO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}